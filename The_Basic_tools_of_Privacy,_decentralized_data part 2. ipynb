{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The Basic tools of Privacy, decentralized data .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyadip1995/Federated-Learning/blob/master/The_Basic_tools_of_Privacy%2C_decentralized_data_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qEG4QRimUaP7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "\n",
        "\n",
        "###Centralized vs Decentralized vs Distributed systems\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1094/1*WG5_xDDwHv0lMaVUYLNbVA.png)\n",
        "\n",
        "\n",
        "\n",
        "###Centralized\n",
        "Centralized systems directly control the operation of the individual units and flow of information from a single center. All individuals are directly dependent on the central power to send and receive information, and to be commanded.\n",
        "\n",
        "single server\n",
        "easy to publish\n",
        "difficult to scale\n",
        "single point of failure\n",
        "Examples (Google, Facebook, Amazon, etc.)\n",
        "\n",
        "###Distributed\n",
        "Distributed systems spread computation across multiple nodes instead of just one. Google for example has adopted a distributed architecture internally to speed up computing and data latency. This means that a system can be both centralized and distributed.\n",
        "\n",
        "Examples (Google, Facebook, Amazon, etc.)\n",
        "\n",
        "###Decentralized\n",
        "\n",
        "Decentralized systems are ones where no node is telling any other node what to do. Bitcoin is both distributed because its timestamped public ledger, the blockchain, resides on multiple computer and decentralized because if one node goes down, the network is still able to operate.\n",
        "\n",
        "*     Multiple Servers\n",
        "\n",
        "*   Demand and Failures better handled\n",
        "*   Examples (Bitcoin, Ethereum, Steemit)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MDNljrtHWk5K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "\n",
        "Know PyTorch - if not then take the http://fast.ai course and come back\n",
        "Read the PySyft Framework Paper https://arxiv.org/pdf/1811.04017.pdf! This will give you a thorough background on how PySyft is constructed which will help things make more sense.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Bn80Ici_uoSQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Now Lets look at some code that can help us understand the basic building blocks of private data"
      ]
    },
    {
      "metadata": {
        "id": "wzNRpflUvNZB",
        "colab_type": "code",
        "outputId": "83a19721-28cd-4794-ee66-ed96ff6799d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/OpenMined/PySyft.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 19909 (delta 85), reused 107 (delta 53), pack-reused 19740\u001b[K\n",
            "Receiving objects: 100% (19909/19909), 26.68 MiB | 20.22 MiB/s, done.\n",
            "Resolving deltas: 100% (12609/12609), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oVJeeqiWunhp",
        "colab_type": "code",
        "outputId": "99a266bf-f405-4024-c6e1-f24cf7a4442a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# Run this cell to see if things work\n",
        "import syft as sy\n",
        "from syft.frameworks.torch.tensors.interpreters import PointerTensor\n",
        "from syft.frameworks.torch.tensors.decorators import LoggingTensor\n",
        "import sys\n",
        "import torch\n",
        "hook = sy.TorchHook(torch)\n",
        "from torch.nn import Parameter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.tensor([1,2,3,4,5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "9QCh_tFZwoGB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So - the first question you may be wondering is - How in the world do we train a model on data we don't have access to?\n",
        "\n",
        "Well, the answer is surprisingly simple. If you're used to working in PyTorch, then you're used to working with torch. Tensor objects"
      ]
    },
    {
      "metadata": {
        "id": "s-KHLi7dxjlY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sending Tensors to Bob's Machine\n",
        "\n",
        "Whereas normally we would perform data science / deep learning on the machine which holds the data, now we want to perform this kind of computation on some other machine. More specifically, we can no longer simply assume that the data is on our local machine.\n",
        "\n",
        "Thus, instead of using Torch tensors, we're now going to work with pointers to tensors. Let me show you what I mean. First, let's create a \"pretend\" machine owned by a \"pretend\" person - we'll call him Bob.\n",
        "\n",
        "Let's say Bob's machine is on another planet - perhaps on Mars! But, at the moment the machine is empty. Let's create some data so that we can send it to Bob and learn about pointers!\n",
        "\n",
        "\n",
        "And now - let's send our tensors to Bob!!"
      ]
    },
    {
      "metadata": {
        "id": "0xNGmSZnwMw6",
        "colab_type": "code",
        "outputId": "f742e0b7-40f0-4a05-ef6d-bc61ff587d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3,4,5])\n",
        "y = x + x\n",
        "print(y)\n",
        "\n",
        "#Obviously, using these super fancy (and powerful!) tensors is important but also requires you to have the data on your local machine. This is where our journey begins.\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "\n",
        "x = torch.tensor([1,2,3,4,5])\n",
        "y = torch.tensor([1,1,1,1,1])\n",
        "\n",
        "x_ptr = x.send(bob)#Send tensors to bob\n",
        "y_ptr = y.send(bob)\n",
        "\n",
        "bob._objects"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2,  4,  6,  8, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5436207437: tensor([1, 1, 1, 1, 1]), 58235070220: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "OffX0SICxbtI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "BOOM! Now Bob has two tensors!"
      ]
    },
    {
      "metadata": {
        "id": "eDj7NV_SyE04",
        "colab_type": "code",
        "outputId": "968933bf-bacb-4c18-fa40-cd6cc5b65704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "z = x_ptr + x_ptr\n",
        "\n",
        "z\n",
        "\n",
        "bob._objects"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4033011783: tensor([ 2,  4,  6,  8, 10]),\n",
              " 5436207437: tensor([1, 1, 1, 1, 1]),\n",
              " 58235070220: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "G2uwIrmQtyol",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now notice something. When we called x.send(bob) it returned a new object that we called x_ptr. This is our first pointer to a tensor. Pointers to tensors do NOT actually hold data themselves. Instead, they simply contain the metadata about a tensor (with data) stored on another machine. The purpose is to give us an intuitive API to tell the other machine to compute functions using this tensor. Let's take a look at the metadata that pointers contain."
      ]
    },
    {
      "metadata": {
        "id": "qD0EeyFSuqpd",
        "colab_type": "code",
        "outputId": "ce2ab9e7-b0e6-4f11-d96b-af04022fecb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x_ptr"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:1480744114 -> bob:58235070220]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "4PK1N2TDuu62",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check out that metadata!\n",
        "\n",
        "There are two main attributes specific to pointers:\n",
        "\n",
        "x_ptr.location : bob, the location, a reference to the location that the pointer is pointing to\n",
        "x_ptr.id_at_location : <random integer>, the id where the tensor is stored at location\n",
        "They are printed in the format <id_at_location>@<location>\n",
        "\n",
        "There are also other more generic attributes:\n",
        "\n",
        "x_ptr.id : <random integer>, the id of oui pointer tensor, it was allocated randomly\n",
        "x_ptr.owner : me, the worker which owns the pointer tensor, here it's the local worker, named \"me\""
      ]
    },
    {
      "metadata": {
        "id": "m8Wcxa1wuzWO",
        "colab_type": "code",
        "outputId": "b5a3d527-c86f-48fb-c9a5-6c3f21f53a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x_ptr.location\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #tensors:3>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "BpyvnQsnveW0",
        "colab_type": "code",
        "outputId": "c0b3a86e-30a3-4c05-e92f-9fc4bf42df55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "bob"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #tensors:3>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "ihDeRB9bvg5W",
        "colab_type": "code",
        "outputId": "cd90dcdf-2fb7-441a-857e-3df080e250ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "bob== x_ptr.location"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Lc3v84IFvm0w",
        "colab_type": "code",
        "outputId": "5d4d73c7-15ef-4b4a-93ed-2bde72e7d7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x_ptr.id_at_location"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58235070220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "h1HwKlc4vrad",
        "colab_type": "code",
        "outputId": "20d7d90d-546a-46bd-a982-132f9efa37d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_ptr.owner"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:me #tensors:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "6Zg2gZd9vxy9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may wonder why the local worker which owns the pointer is also a VirtualWorker, although we didn't create it. Fun fact, just like we had a VirtualWorker object for Bob, we (by default) always have one for us as well. This worker is automatically created when we called hook = sy.TorchHook() and so you don't usually have to create it yourself."
      ]
    },
    {
      "metadata": {
        "id": "9GnLuFpBv1cY",
        "colab_type": "code",
        "outputId": "1a9b695a-e1a0-4f98-e887-ffa322c73866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "me= sy.local_worker\n",
        "me\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:me #tensors:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "fRMQeaZywaEW",
        "colab_type": "code",
        "outputId": "f96708c4-188c-4d77-ed99-b28a6804d4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "me == x_ptr.owner"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "ihveN0kLwhEV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And finally, just like we can call .send() on a tensor, we can call .get() on a pointer to a tensor to get it back!!!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "StheV-K7wiJ-",
        "colab_type": "code",
        "outputId": "450c5b07-450e-4524-c900-0acf5a000ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x_ptr"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:1480744114 -> bob:58235070220]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEB2aADo_fiV",
        "colab_type": "code",
        "outputId": "51002efd-3dc5-4331-9bc1-2420f2014e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x_ptr.get()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "AbKp0ClY_jwN",
        "colab_type": "code",
        "outputId": "49d6c3f3-25e5-4023-e543-9b547bef82f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "y_ptr\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:83054688871 -> bob:5436207437]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "ywgm3zzr_odT",
        "colab_type": "code",
        "outputId": "176a4538-2165-41d0-aa4b-b041ecf545c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "y_ptr.get()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "IcYn9Wlu_sxW",
        "colab_type": "code",
        "outputId": "c896c674-0c8f-4360-cd74-07700e038fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "z.get()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  4,  6,  8, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "jabDdz9C_wvC",
        "colab_type": "code",
        "outputId": "2eeaf348-51c7-4dff-86df-42c9384ff3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "bob._objects"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "NjwFPV56_6mM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And as you can see... Bob no longer has the tensors anymore!!! They've moved back to our machine!"
      ]
    },
    {
      "metadata": {
        "id": "EdfrRUKJFc-1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using Tensor Pointers\n",
        "So, sending and receiving tensors from Bob is great, but this is hardly Deep Learning! We want to be able to perform tensor operations on remote tensors. Fortunately, tensor pointers make this quite easy! You can just use pointers like you would normal tensors!"
      ]
    },
    {
      "metadata": {
        "id": "tnc9_cW3FeF9",
        "colab_type": "code",
        "outputId": "2bcccec0-bb0e-4e66-d9c2-546b5e520d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3,4,5]).send(bob)\n",
        "y = torch.tensor([1,1,1,1,1]).send(bob)\n",
        "\n",
        "z = x + y\n",
        "z"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:81564910974 -> bob:81564910974]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "H76icm2CFrws",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And voilà!\n",
        "\n",
        "Behind the scenes, something very powerful happened. Instead of x and y computing an addition locally, a command was serialized and sent to Bob, who performed the computation, created a tensor z, and then returned the pointer to z back to us!\n",
        "\n",
        "If we call .get() on the pointer, we will then receive the result back to our machine!"
      ]
    },
    {
      "metadata": {
        "id": "ocm0Jk78FtMG",
        "colab_type": "code",
        "outputId": "1d3bc2c9-ee59-47e2-bafc-fc32547bb001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "z.get()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "0kg5XIHMF9xd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Torch Functions\n",
        "\n",
        "\n",
        "This API has been extended to all of Torch's operations!!!"
      ]
    },
    {
      "metadata": {
        "id": "oCYgXX1JF3mx",
        "colab_type": "code",
        "outputId": "1ec80274-d453-4ad4-a4b8-f5abf52e2db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:53443883314 -> bob:22174642389]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "6MxTtp_TGE61",
        "colab_type": "code",
        "outputId": "764d3b5c-89d0-4275-8997-4a8391cf7cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:76221350567 -> bob:36008129613]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "QBogj5vFGGdN",
        "colab_type": "code",
        "outputId": "108905f3-475b-4388-9520-4341c14908bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "z=torch.add(x,y)\n",
        "z\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:79838982842 -> bob:79838982842]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "NiG6I3PoGMsH",
        "colab_type": "code",
        "outputId": "d7f1487d-a1ea-49e9-a04c-53c38933967f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "z.get()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "zoyX-a-FGQd9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Variables (including backpropagation!)"
      ]
    },
    {
      "metadata": {
        "id": "SW0F1e-pGUB0",
        "colab_type": "code",
        "outputId": "34985015-bc44-4018-e750-028f292d1901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3,4,5.], requires_grad=True).send(bob)\n",
        "y = torch.tensor([1,1,1,1,1.], requires_grad=True).send(bob)\n",
        "\n",
        "z = (x + y).sum()\n",
        "z.backward()\n",
        "x=x.get()\n",
        "x"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "GQ_8vA75GYJJ",
        "colab_type": "code",
        "outputId": "76876b93-2143-4565-a7f1-c533c97db6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "Euh2k9QjGlVC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So as you can see, the API is really quite flexible and capable of performing nearly any operation you would normally perform in Torch on remote data. This lays the groundwork for our more advanced privacy preserving protocols such as Federated Learning, Secure Multi-Party Computation, and Differential Privacy !\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wIBvYn2vmeu8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Introduction To federated Learning\n",
        "\n",
        "\n",
        "Federated Learning is an alternative approach to machine learn-\n",
        "ing where data is not collected. In a nutshell, the parts of the algorithms that touch the data are moved to the users’ computers. Users collaboratively help to train a model by using their locally available data to compute model improvements. Instead of sharing their data, users then send only\n",
        "these abstract improvements back to the server.\n",
        "This approach is much more privacy-friendly and flexible. Applications\n",
        "on mobile phones provide examples where this is especially evident. Users\n",
        "generate vast amounts of data through interaction with the device. This\n",
        "data is often deeply private in nature and should not be shared completely\n",
        "with a server. Federated Learning still allows training a common model\n",
        "using all this data, without necessarily sacrificing computational power or\n",
        "missing out on smarter algorithms. (Img:- Google AI blog). A primary example how federated learning works.\n",
        "\n",
        "\n",
        "![alt text](https://1.bp.blogspot.com/-K65Ed68KGXk/WOa9jaRWC6I/AAAAAAAABsM/gglycD_anuQSp-i67fxER1FOlVTulvV2gCLcB/s1600/FederatedLearning_FinalFiles_Flow%2BChart1.png)"
      ]
    },
    {
      "metadata": {
        "id": "WwdlPk-coBPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Summary\n",
        "\n",
        "\n",
        "In this blog post we have learnt how to use the basic blocks of privacy- sending and receiving tensors and other torch functions . As mentioned before, this lays the groundwork for more advanced privacy, such techniques such as federated learning, which we have just been introduced to. In the next blog post we will discuss federated learning in details.\n",
        "\n",
        "\n",
        "More reading material and some of my sources\n",
        "\n",
        "1. Google API blog post https://ai.googleblog.com/2017/04/federated-learning-collaborative.html\n",
        "2. Andrew Trask  https://www.openmined.org/\n",
        "3. Siraj Raval."
      ]
    }
  ]
}
